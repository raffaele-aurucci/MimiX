<!DOCTYPE html>
<html lang="it">

<head>
  <meta charset="utf-8">
  <meta http-equiv="Cache-control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
  <title>Face Landmarker</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: #000;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
    }

    video {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      transform: rotateY(180deg);
    }
  </style>
</head>

<body>
<video id="webcam" autoplay playsinline></video>

<script type="module">
  import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
  const { FaceLandmarker, FilesetResolver } = vision;

  let faceLandmarker;
  let webcamRunning = false;
  const video = document.getElementById("webcam");

  // Function used to load model and enable webcam
  async function setupFaceLandmarker() {
    const filesetResolver = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
    );

    faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
      baseOptions: {
        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
        delegate: "GPU"
      },
      outputFaceBlendshapes: true,
      runningMode: "VIDEO",
      numFaces: 1,
    });

    await enableWebcam();
  }

  async function enableWebcam() {
    try {
      // The navigator.mediaDevices.getUserMedia() method is a Web API that allows access to multimedia streams
      // (video and/or audio) from the user's device, such as the camera or microphone.
      // The default camera for video is frontal camera.
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      if (!webcamRunning) {
        // when the browser starts looking for the audio/video execute predictWebcam()
        video.addEventListener("loadeddata", predictWebcam);
        webcamRunning = true;
      }
    } catch (error) {
      console.error("Error accessing webcam", error);
    }
  }

  async function predictWebcam() {
    // checks if webcam running and model is loaded
    if (!webcamRunning || !faceLandmarker) return;

    // current timestamp
    const startTimeMs = performance.now();

    // executes prediction for landmarks and blandshapes asynchronously
    const results = await faceLandmarker.detectForVideo(video, startTimeMs);

    // console.log(results.faceLandmarks)
    // console.log(results.faceBlendshapes)

    // sends the results to Flutter via POST message
    if (results?.faceLandmarks?.length && results.faceBlendshapes) {
      FaceDetection?.postMessage(JSON.stringify({
        face_landmarks: results.faceLandmarks[0],
        face_blendshapes: results.faceBlendshapes[0],
        face_detected: true
      }));
    } else {
      FaceDetection?.postMessage(JSON.stringify({
        face_detected: false
      }));
    }

    // It calls predictWebcam to continue the prediction cycle, creating a continuous loop for face tracking
    window.requestAnimationFrame(predictWebcam);
  }

  // Controls the change visibility of page, such as when the user puts the app in background
  document.addEventListener("visibilitychange", async () => {

    // stop prediction and disable webcam if document is hidden
    if (document.hidden) {
      webcamRunning = false;
      const stream = video.srcObject;

      // stop all track video in the stream, releasing resources
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }

      // remove the previous listener
      video.removeEventListener("loadeddata", predictWebcam);
    } else {
      // checks if the model has loaded, for example when the user puts the app in the background before the model is loading
      if (faceLandmarker && !webcamRunning) {
        await enableWebcam();
      } else if (!faceLandmarker) {
        await setupFaceLandmarker();
      }
    }
  });

  // Load FaceLandmarker model and enable the webcam
  setupFaceLandmarker();

</script>
</body>

</html>
